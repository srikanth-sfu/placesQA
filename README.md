# placesQA
Main Repository for Muralidharan et al., "PlacesQA: Towards Automatic Answering of Questions on the Web"

## [PlacesQA: Towards Automatic Answering of Questions on the Web. Srikanth Muralidharan, Akash Abdu Jyothi, Nelson Nauata, Fred Tung, Greg Mori. Arxiv Version](https://www.arxiv.org/)

## Contents
0. [Abstract](abstract)
0. [Task](#task)
0. [Dataset](#dataset)
0. [Model](#model)
0. [Experiments](#experiments)
0. [License and Citation](#license-and-citation)

## Abstract

Web users often post questions: "Does hotel X have a pool?", "Is museum Y wheelchair accessible?". The potential to automate the answering process presents an exciting challenge for AI systems, with many practical applications. However, to the best of our knowledge, there are not yet any public datasets for general question answering on the web. In this paper, we introduce the PlacesQA dataset, which contains 9,750 questions and answers about 750 unique places, including hotels, museums and nightlife venues, derived from questions asked by real users of travel websites.  This dataset serves as a testbed for general question answering.  For concreteness, we also provide sets of 73,148 and 181,266 images from these 750 places, obtained via web searches.  We show that images of these places on the web provide a rich source of information that can be potentially leveraged by an automatic question answering agent.

## Task

<img src="https://github.com/sri3705/placesQA/blob/master/images/qa_pull.jpg" alt="Our Task" height="400" >

**Figure 1** This paper takes a first step towards general question answering on the web (middle), in which an AI agent is given a user question and is tasked
with acquiring relevant images (and other complementary modes of information) from the web to produce an accurate answer. Our PlacesQA dataset consists of
``canonical" questions and answers covering 750 unique places, including hotels, museums, and nightlife venues. The visual QA example is from
[AntolICCV2015](https://arxiv.org/pdf/1505.00468v6.pdf).


## Dataset

## You could download the dataset [here](https://arxiv.org).

## Model

## Experiments

## License and Citation

Source code is released under the **BSD 2-Clause license**

If you are using our dataset, please site the following publication:

###### Webpage inspired from [Ibrahim et al. CVPR2016](https://github.com/mostafa-saad/deep-activity-rec).
